# Проект 8-го спринта - Потоковая обработка данных

### Описание
В проекте реализован сервис агрегатора доставки, который:
1. Читает данные об акциях из **Kafka** с помощью **Spark Structured Streaming** и **Python** в режиме реального времени.
2. Получает список подписчиков из базы данных **Postgres**.
3. Объединяет данные из Kafka с данными из БД. (Join потоковых и статичных данных)
4. Отправляет выходное сообщение в Kafka с информацией об акции, пользователе со списком избранного и ресторане, а также вставляет данные в Postgres.

## Запуск проекта
1. Загрузить отправку в поток Kafka информации по акциям ресторанов `/src/test_message.txt`
2. Создать таблицу для приема сообщений в базе PostgreSQL `/src/ddl.sql`
3. Запустить основную программу обрабоки потока `/src/main_15.py`

### Инструменты
Kakfa, PostgreSQL, Pyspark, SparkStreaming
